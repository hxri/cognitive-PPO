global_step=8, episodic_return=[-1.]
global_step=28, episodic_return=[-1.]
global_step=44, episodic_return=[-1.]
global_step=52, episodic_return=[-1.]
global_step=56, episodic_return=[-1.]
global_step=60, episodic_return=[-1.]
global_step=68, episodic_return=[-1.]
global_step=72, episodic_return=[-1.]
global_step=96, episodic_return=[-1.]
Moviepy - Building video D:\Masters\Projects\thesis\cognitive-PPO\videos\MiniGrid-Dynamic-Obstacles-Random-10x10-v0__playground_gridworld__1__1683221649\rl-video-episode-0.mp4.
Moviepy - Writing video D:\Masters\Projects\thesis\cognitive-PPO\videos\MiniGrid-Dynamic-Obstacles-Random-10x10-v0__playground_gridworld__1__1683221649\rl-video-episode-0.mp4
Moviepy - Done !
Moviepy - video ready D:\Masters\Projects\thesis\cognitive-PPO\videos\MiniGrid-Dynamic-Obstacles-Random-10x10-v0__playground_gridworld__1__1683221649\rl-video-episode-0.mp4
global_step=104, episodic_return=[-1.]
global_step=112, episodic_return=[-1.]
global_step=132, episodic_return=[-1.]
global_step=144, episodic_return=[-1.]
global_step=196, episodic_return=[-1.]
global_step=224, episodic_return=[-1.]
global_step=260, episodic_return=[-1.]
global_step=292, episodic_return=[-1.]
global_step=296, episodic_return=[-1.]
global_step=300, episodic_return=[-1.]
global_step=312, episodic_return=[-1.]
global_step=380, episodic_return=[-1.]
global_step=392, episodic_return=[-1.]
global_step=408, episodic_return=[-1.]
global_step=436, episodic_return=[0.99937]
global_step=476, episodic_return=[-1.]
global_step=480, episodic_return=[-1.]
global_step=488, episodic_return=[-1.]
global_step=508, episodic_return=[-1.]
SPS:  86
C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\gymnasium\envs\registration.py:523: DeprecationWarning: [33mWARN: The environment MiniGrid-Dynamic-Obstacles-Random-10x10-v0 is out of date. You should consider upgrading to version `v2`.
  logger.deprecation(
global_step=548, episodic_return=[-1.]
global_step=568, episodic_return=[-1.]
global_step=644, episodic_return=[-1.]
global_step=672, episodic_return=[-1.]
global_step=712, episodic_return=[-1.]
global_step=736, episodic_return=[-1.]
global_step=748, episodic_return=[-1.]
global_step=776, episodic_return=[-1.]
global_step=788, episodic_return=[-1.]
global_step=856, episodic_return=[-1.]
global_step=900, episodic_return=[-1.]
global_step=936, episodic_return=[-1.]
global_step=948, episodic_return=[-1.]
global_step=992, episodic_return=[-1.]
global_step=1004, episodic_return=[-1.]
global_step=1020, episodic_return=[0.98776]
SPS:  110
global_step=1032, episodic_return=[-1.]
global_step=1040, episodic_return=[-1.]
global_step=1232, episodic_return=[-1.]
global_step=1276, episodic_return=[-1.]
global_step=1280, episodic_return=[-1.]
global_step=1308, episodic_return=[-1.]
global_step=1336, episodic_return=[-1.]
global_step=1344, episodic_return=[-1.]
global_step=1388, episodic_return=[-1.]
global_step=1412, episodic_return=[-1.]
global_step=1456, episodic_return=[-1.]
global_step=1492, episodic_return=[-1.]
global_step=1496, episodic_return=[-1.]
global_step=1512, episodic_return=[-1.]
global_step=1532, episodic_return=[-1.]
SPS:  120
global_step=1540, episodic_return=[-1.]
global_step=1584, episodic_return=[-1.]
global_step=1612, episodic_return=[-1.]
global_step=1688, episodic_return=[-1.]
global_step=1756, episodic_return=[-1.]
global_step=1804, episodic_return=[-1.]
global_step=1816, episodic_return=[-1.]
global_step=1820, episodic_return=[-1.]
global_step=1888, episodic_return=[-1.]
global_step=1924, episodic_return=[-1.]
global_step=1948, episodic_return=[-1.]
SPS:  128
global_step=2204, episodic_return=[-1.]
global_step=2228, episodic_return=[-1.]
global_step=2292, episodic_return=[-1.]
SPS:  133
global_step=2744, episodic_return=[-1.]
SPS:  137
global_step=3492, episodic_return=[-1.]
global_step=3508, episodic_return=[-1.]
global_step=3532, episodic_return=[-1.]
global_step=3580, episodic_return=[-1.]
SPS:  141
global_step=3752, episodic_return=[-1.]
global_step=3796, episodic_return=[-1.]
SPS:  143
global_step=4552, episodic_return=[-1.]
SPS:  145
SPS:  147
SPS:  148
global_step=6136, episodic_return=[-1.]
SPS:  149
SPS:  145
global_step=6872, episodic_return=[-1.]
global_step=7016, episodic_return=[-1.]
SPS:  141
global_step=7468, episodic_return=[-1.]
global_step=7536, episodic_return=[-1.]
global_step=7588, episodic_return=[-1.]
global_step=7636, episodic_return=[-1.]
SPS:  139
global_step=8016, episodic_return=[-1.]
global_step=8132, episodic_return=[-1.]
SPS:  137
SPS:  136
global_step=8928, episodic_return=[-1.]
SPS:  135
SPS:  135
global_step=9908, episodic_return=[-1.]
global_step=10004, episodic_return=[-1.]
SPS:  134
global_step=10472, episodic_return=[-1.]
SPS:  134
SPS:  134
SPS:  133
global_step=11940, episodic_return=[-1.]
global_step=12164, episodic_return=[-1.]
global_step=12184, episodic_return=[-1.]
global_step=12272, episodic_return=[-1.]
SPS:  134
SPS:  134
SPS:  133
SPS:  135
SPS:  136
global_step=14416, episodic_return=[-1.]
global_step=14548, episodic_return=[-1.]
SPS:  138
SPS:  138
SPS:  139
SPS:  141
SPS:  140
global_step=16932, episodic_return=[-1.]
SPS:  139
SPS:  139
SPS:  140
SPS:  141
SPS:  141
SPS:  142
SPS:  142
SPS:  142
SPS:  143
global_step=21644, episodic_return=[-1.]
SPS:  142
SPS:  143
SPS:  143
SPS:  143
SPS:  143
SPS:  143
SPS:  143
SPS:  143
SPS:  143
SPS:  143
SPS:  143
SPS:  143
SPS:  143
Traceback (most recent call last):
  File "D:\Masters\Projects\thesis\cognitive-PPO\playground_gridworld.py", line 408, in <module>
    optimizer.step()
  File "C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\torch\optim\optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\torch\optim\adam.py", line 141, in step
    adam(
  File "C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\torch\optim\adam.py", line 281, in adam
    func(params,
  File "C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\torch\optim\adam.py", line 391, in _single_tensor_adam
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
             ^^^^^^^^^^^^^^^^^
KeyboardInterrupt