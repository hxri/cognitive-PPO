C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\gymnasium\envs\registration.py:523: DeprecationWarning: [33mWARN: The environment MiniGrid-Dynamic-Obstacles-Random-10x10-v0 is out of date. You should consider upgrading to version `v2`.
  logger.deprecation(
global_step=8, episodic_return=[-1.]
global_step=28, episodic_return=[-1.]
global_step=44, episodic_return=[-1.]
global_step=52, episodic_return=[-1.]
global_step=56, episodic_return=[-1.]
global_step=60, episodic_return=[-1.]
SPS:  16
global_step=68, episodic_return=[-1.]
global_step=72, episodic_return=[-1.]
global_step=96, episodic_return=[-1.]
global_step=100, episodic_return=[0.99928]
global_step=112, episodic_return=[-1.]
Moviepy - Building video D:\Masters\Projects\thesis\cognitive-PPO\videos\MiniGrid-Dynamic-Obstacles-Random-10x10-v0__playground_gridworld__1__1683223145\rl-video-episode-0.mp4.
Moviepy - Writing video D:\Masters\Projects\thesis\cognitive-PPO\videos\MiniGrid-Dynamic-Obstacles-Random-10x10-v0__playground_gridworld__1__1683223145\rl-video-episode-0.mp4
Moviepy - Done !
Moviepy - video ready D:\Masters\Projects\thesis\cognitive-PPO\videos\MiniGrid-Dynamic-Obstacles-Random-10x10-v0__playground_gridworld__1__1683223145\rl-video-episode-0.mp4
global_step=116, episodic_return=[-1.]
SPS:  22
global_step=132, episodic_return=[-1.]
global_step=144, episodic_return=[-1.]
global_step=176, episodic_return=[-1.]
global_step=188, episodic_return=[-1.]
SPS:  27
global_step=224, episodic_return=[-1.]
SPS:  30
global_step=296, episodic_return=[-1.]
global_step=308, episodic_return=[-1.]
global_step=312, episodic_return=[-1.]
SPS:  32
SPS:  34
global_step=388, episodic_return=[-1.]
global_step=436, episodic_return=[-1.]
SPS:  35
SPS:  36
global_step=528, episodic_return=[-1.]
global_step=540, episodic_return=[-1.]
global_step=568, episodic_return=[-1.]
SPS:  37
SPS:  38
global_step=660, episodic_return=[-1.]
SPS:  39
SPS:  40
SPS:  40
SPS:  41
global_step=916, episodic_return=[-1.]
SPS:  41
global_step=1004, episodic_return=[-1.]
SPS:  42
SPS:  42
SPS:  42
SPS:  43
SPS:  43
SPS:  43
SPS:  43
SPS:  44
SPS:  44
SPS:  44
SPS:  44
SPS:  44
SPS:  44
SPS:  45
SPS:  44
SPS:  45
SPS:  45
SPS:  45
SPS:  45
SPS:  45
SPS:  45
SPS:  44
SPS:  45
SPS:  45
SPS:  45
SPS:  45
SPS:  45
SPS:  45
SPS:  45
SPS:  45
SPS:  45
SPS:  45
SPS:  45
SPS:  44
SPS:  44
SPS:  44
SPS:  44
SPS:  44
SPS:  44
SPS:  44
SPS:  44
SPS:  44
SPS:  44
global_step=3752, episodic_return=[-1.]
SPS:  43
SPS:  43
SPS:  43
SPS:  43
SPS:  43
SPS:  43
SPS:  43
SPS:  43
SPS:  43
SPS:  43
SPS:  43
SPS:  43
SPS:  43
SPS:  42
global_step=4672, episodic_return=[-1.]
SPS:  42
global_step=4692, episodic_return=[-1.]
SPS:  42
SPS:  42
SPS:  42
SPS:  42
SPS:  42
global_step=5000, episodic_return=[-1.]
global_step=5048, episodic_return=[-1.]
SPS:  42
global_step=5064, episodic_return=[0.99856]
global_step=5092, episodic_return=[-1.]
global_step=5104, episodic_return=[-1.]
global_step=5116, episodic_return=[-1.]
SPS:  42
global_step=5144, episodic_return=[-1.]
SPS:  42
global_step=5224, episodic_return=[-1.]
global_step=5236, episodic_return=[-1.]
SPS:  42
SPS:  41
global_step=5376, episodic_return=[-1.]
SPS:  41
global_step=5396, episodic_return=[0.99613]
SPS:  41
global_step=5452, episodic_return=[-1.]
global_step=5472, episodic_return=[-1.]
SPS:  41
global_step=5512, episodic_return=[-1.]
SPS:  41
global_step=5584, episodic_return=[-1.]
global_step=5608, episodic_return=[-1.]
global_step=5620, episodic_return=[0.99973]
SPS:  41
global_step=5652, episodic_return=[-1.]
global_step=5672, episodic_return=[-1.]
global_step=5680, episodic_return=[-1.]
SPS:  41
global_step=5704, episodic_return=[-1.]
SPS:  41
global_step=5792, episodic_return=[-1.]
global_step=5796, episodic_return=[-1.]
global_step=5824, episodic_return=[-1.]
SPS:  41
global_step=5888, episodic_return=[-1.]
SPS:  41
global_step=5896, episodic_return=[-1.]
global_step=5940, episodic_return=[-1.]
SPS:  41
SPS:  41
global_step=6032, episodic_return=[-1.]
global_step=6036, episodic_return=[-1.]
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
global_step=6760, episodic_return=[-1.]
SPS:  41
SPS:  41
global_step=6904, episodic_return=[-1.]
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
SPS:  41
global_step=7584, episodic_return=[-1.]
SPS:  41
global_step=7652, episodic_return=[-1.]
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
global_step=8104, episodic_return=[-1.]
global_step=8120, episodic_return=[0.98794]
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
SPS:  40
Traceback (most recent call last):
  File "D:\Masters\Projects\thesis\cognitive-PPO\playground_gridworld.py", line 408, in <module>
    optimizer.step()
  File "C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\torch\optim\optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\torch\optim\adam.py", line 141, in step
    adam(
  File "C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\torch\optim\adam.py", line 281, in adam
    func(params,
  File "C:\Users\hxri\miniconda3\envs\cogppo\Lib\site-packages\torch\optim\adam.py", line 345, in _single_tensor_adam
    exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)
KeyboardInterrupt